services:
  my_project_jupyter:
    build:
      context: .
      dockerfile: docker/Dockerfile
    runtime: nvidia
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu
                - utility
                - compute
              driver: nvidia
              count: all
    devices:
      - "/dev/nvidia0:/dev/nvidia0"
      - "/dev/nvidia1:/dev/nvidia1"
      - "/dev/nvidia2:/dev/nvidia2"
      - "/dev/nvidia3:/dev/nvidia3"
      - "/dev/nvidiactl:/dev/nvidiactl"
      - "/dev/nvidia-uvm:/dev/nvidia-uvm"
      - "/dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      stack:
        soft: 67108864
        hard: 67108864
    volumes:
      - .:/workspace:z
      # Shared huggingface cache
      - /mnt/raid/data/shared-cache/huggingface:/cache/huggingface:z
      # To add a user data volume, uncomment the following line.
      # Note that the directory must be created before running the container.
      # - /mnt/raid/data/${USER}:/user_data:z
      # To add a project data volume, uncomment the following line.
      # Note that the directory must be created before running the container.
      # - /mnt/raid/data/${PROJECT}:/project_data:z
    ports:
      - "${JUPYTER_PORT}:9999"
    environment:
      - UID=${UID}
      - GID=${GID}
      - USER=${USER}
      - PYTHONPATH=/workspace
      - HF_HUB_CACHE=/cache/huggingface
    command: |
      jupyter lab
        --ip=0.0.0.0
        --port=9999 
        --NotebookApp.use_redirect_file=False
        --no-browser
        --notebook-dir=/workspace/notebooks
        --NotebookApp.custom_display_url="http://localhost:${JUPYTER_PORT}"
